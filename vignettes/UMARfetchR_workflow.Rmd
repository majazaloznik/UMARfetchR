---
title: "UMARfetchR workflow"
output: 
  bookdown::html_document2:
    base_format: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{UMARfetchR workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This document gives a high level overview of the `UMARfetchR` package and its functionalities and how it fits into the UMAR data workflow.

This is one of a family of data fetching packages, which include `SURSfetchR`, `MFfetchR` and others, providing specialised functions to download, extract and clean up data from these sources and prepare it into a suitable format for ingestion into the UMAR data platform. The latter part of the workflow is handled by the `UMARaccessR` package.

`UMARfetchR` is special in that it is intended to be applied to data prepared by our colleagues at UMAR, while the other fetching packages are all used to automatically ETL data from specific sources.

# Data 

Each data series must have:

* metadata or structural data, which the author prepares in a specified format and which gets imported into the database once. The format is one row per series and more details are given in section \@ref(meta). Each author has one structural file to which they may append new series.
* the timeseries data, which is formatted column-wise and more details are given in section \@ref(data-specs). This file is updated with new rows when more data becomes available and is ingested into the database on a regular basis. 


# Workflow

Individual authors are assigned a folder on the network drive with two template files: a metadata file and a data file. Following the instructions they enter the metadata for each series in one file (one row per series) and the data in the second (one column per series). Both files can also be updated by adding new series and/or adding new data.  

A **fetching** script will be run regularly via Task Scheduler (for now anyway), to pick up any changes to the files and update the database. 

## Once per database

The `insert_new_source()` function is run only once as it inserts the source `UMAR` and the highest level category hierarchy. 

## Once per author

For each new author the `add_new_author()` function does the following:

* adds the author to the database - which also checks for uniqueness of initials, otherwise exits with a warning. If author can be added then:
* `add_author_folder` creates a folder for them on `O:\Avtomatizacija\umar-data\` (or wherever else you want to) and also:
* runs `create_structure_template_excel()` which creates an Excel template in their folder to populate with their metadata and is named `umar_serije_metadata_<authorinitials>.xlsx`. 
* Also runs `create_data_template_excel()`, which creates a data template file in the same location. ^[ The authors are given instructions as to how to do this, which are also a vignette in this package [here](Navodila_za_avtorje.html)]. 
* each author also represents a `category` in the database. So `insert_new_category` and `insert_new_category_relationship` are run with the author name as the category.^[Although eventually other categories can be added, but there is no expectation right now that this functionality will be needed.]

Once this is done, the maintainer needs to manually give the author permissions to modify the contents of the files in their folder. Or rather ask Saša to do it. 

## Once per series 

For each new series, the author prepares a row in the metadata Excel file with 8 or 9 columns. The filename is the input for the `main_structure()` function which does the following:

* reads the file with the metadata
* parses it and checks the data is reasonable with `parse_structure()` , which also computes columns (9), 10 and 11.
* runs `prep_and_import_structure()`, which writes all the *new series'* metadata to the database 
* then this dataframe also written back to the Excel file with the `update_structure_excel()`. Next time new series are added to the table, the prep&insert function will skip the existing series. 
* *This is important: you cannot make changes to the metadata of series you have already imported. The expected procedure is to create a new series.* (I mean a maintainer can always go into the database and fix stuff manually.) Anyway, the funciton treat all series with 11 columns as old and they are not imported again.

## Once per data update

Each time an author wants to update their data, they update the data Excel file by adding the new rows for the new time periods.
 
The function `main_data()` is an umbrella function that does the following:

* reads the file with the data
* parses it and checks the data is reasonable `parse_data()`, which also checks if there is any difference with the data already in the database.
* `prep_and_import_data()` then imports it into the database if needed.

# Specifications {#specs}


## Structre metadata specs {#meta}

The `create_structure_template_excel()` creates a template with nine columns, eight of which *must* be filled by the author. An additional two columns are calculated at import. 

* **source**: if we have done any calculations, the first one is UMAR. the second and further comma-separated ones are the original data sources. If the data being imported has not been manipulated in any way and is only imported because the package for importing from that source doesn't exist yet, the source is reversed: first the original and then UMAR. No spaces are allowed an a max of 8 characters (the second condition is just a recommendation though).

* **author**: full name of author, must be the same as the one used in the umar_authors table in the database. 


* **table_name**: descriptive name grouping a bunch of series that have the same dimensions
* **dimensions**: name of dimensions - at least one. If there are more, they have to be separated by "--"
* **dimension_levels_text**: the level text and codes need to match in number, and also between series. So if you have two dimensions, you need ot have a level_text for each and a level_code for each, again separated by `"--"`
* **dimension_levels_code**: here is an example: The dimensions might be `"geography--gender"`, and then the dimension levels text could be for one series `"Ljubljana--moški"` or `"Maribor--ženske"`, and then the codes could be `"lj--m"`, `"mb--f`". The choice of codes is up to the author, but they should be short!
* **unit**: must be one of the units in the database. See instructions for authors for current list. 
* **interval**: "M", "Q" or "A" for now
* **series_name**: descriptive name for series - if this is left empty, the dimension_levels_text will be used instead, which is not ideal, but better than nothing. 

Then there are two additional columns that get computed during the import process:

* **table_code**: is a combination of the author's initials (fron the umar_authors table in the database) and a three digit incremental number. e.g. "MZ003" etc. These are computed automatically based on what is already in the database
* **series_code**: is computed as a combination of the source, the table name, the dimension level codes and the interval. e.g. `"UMAR-SURS--MZ012--LJ--M--Q"`. 

## Data specs 

The data tables must be **tidy**:

* each row represents one time interval
* each column represents a series, using the `series_codes` which result from the `main_structure()` run and can be found in the updated metadata Excel
* therefore each interval type requires it's own worksheet, which should be named "M", "Q", or "A"

The tables must:

* have one and only one column titled **`period`**, which must contain the correctly formatted time e.g. "2020M04" for months or "2023Q4" for quarters and must be incrementally and monotonically increasing i.e. no duplicated period values are allowed.  
* have column names that are legit **`series_code`** values (with the correct interval) and no duplicates
* have their header in the first row ^[Although this is not strictly necessary, because the Excel reading funciton is quite smart here, just don't tell anyone :)]. 

The tables can:

* have series of different lengths - but the period values must exist for the longest series.
* have additional sheets for the author's notes or whatever. 

The tables don't have to:

* have all the series that were in the structure table. But why would you do that? 
* have all the worksheets if the series for them don't exist, but the template creates the three empty sheets anyway.  




